# Use an Alpine base image
FROM python:3.10.12-alpine

# Set environment variables for versions
ENV SCALA_VERSION=2.12.15 \
    DELTA_LAKE_VERSION=2.4.0 \
    HADOOP_VERSION=3 \
    SPARK_VERSION=3.4.4 \
    SPARK_HOME=/opt/spark \
    PATH="${SPARK_HOME}/bin:${SPARK_HOME}/sbin:${PATH}"

# Install required packages and Java 8
RUN apk add --no-cache \
    openjdk8 \
    bash \
    gcc \
    g++ \
    musl-dev \
    git \
    curl \
    wget \
    libmagic \
    linux-headers \
    libc-dev \
    R

RUN pip install --upgrade pip && \
    pip install --no-cache-dir \
    jupyterlab \
    toree \
    pyspark==${SPARK_VERSION} \
    delta-spark==${DELTA_LAKE_VERSION}

# Install Apache Spark
RUN curl -sL "https://downloads.apache.org/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz" | \
    tar -xz -C /opt && \
    mv /opt/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION} $SPARK_HOME

# Install Scala
RUN wget -q https://downloads.lightbend.com/scala/$SCALA_VERSION/scala-$SCALA_VERSION.tgz && \
    tar xzf scala-$SCALA_VERSION.tgz -C /usr/local/ && \
    ln -s /usr/local/scala-$SCALA_VERSION/bin/scala /usr/local/bin/scala && \
    ln -s /usr/local/scala-$SCALA_VERSION/bin/scalac /usr/local/bin/scalac && \
    rm scala-$SCALA_VERSION.tgz

# Set JAVA_HOME
ENV JAVA_HOME=/usr/lib/jvm/java-8-openjdk
ENV PATH="$JAVA_HOME/bin:$PATH"

# Set up Toree
RUN jupyter toree install --spark_home=$SPARK_HOME --interpreters=Scala,PySpark,SparkR,SQL

# Set the working directory
WORKDIR /home

# Create a default startup command
CMD ["jupyter-lab", "--ip=0.0.0.0", "--port=8888", "--no-browser", "--allow-root"]
